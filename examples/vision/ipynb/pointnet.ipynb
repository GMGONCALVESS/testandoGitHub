{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-BInmRYrnAu"
      },
      "source": [
        "# Point cloud classification with PointNet\n",
        "\n",
        "**Author:** [David Griffiths](https://dgriffiths3.github.io)<br>\n",
        "**Date created:** 2020/05/25<br>\n",
        "**Last modified:** 2024/01/09<br>\n",
        "**Description:** Implementation of PointNet for ModelNet10 classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfGlCgEtrnAx"
      },
      "source": [
        "# Point cloud classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7CjImvKrnAx"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Classification, detection and segmentation of unordered 3D point sets i.e. point clouds\n",
        "is a core problem in computer vision. This example implements the seminal point cloud\n",
        "deep learning paper [PointNet (Qi et al., 2017)](https://arxiv.org/abs/1612.00593). For a\n",
        "detailed intoduction on PointNet see [this blog\n",
        "post](https://medium.com/@luis_gonzales/an-in-depth-look-at-pointnet-111d7efdaa1a)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDpe7aNxrnAy"
      },
      "source": [
        "## Setup\n",
        "\n",
        "If using colab first install trimesh with `!pip install trimesh`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh"
      ],
      "metadata": {
        "id": "ogf7tmOEu2eG",
        "outputId": "375823d3-76a0-4c31-d6ca-a0ac0fd91542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.6.6-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from trimesh) (2.0.2)\n",
            "Downloading trimesh-4.6.6-py3-none-any.whl (709 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/709.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m706.6/709.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AuH0dfItrnAy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "import trimesh\n",
        "import numpy as np\n",
        "from tensorflow import data as tf_data\n",
        "from keras import ops\n",
        "import keras\n",
        "from keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "keras.utils.set_random_seed(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dayKzCVVrnAz"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "We use the ModelNet10 model dataset, the smaller 10 class version of the ModelNet40\n",
        "dataset. First download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6p54Gz0rnAz"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = keras.utils.get_file(\n",
        "    \"modelnet.zip\",\n",
        "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doXiPsm-rnA0"
      },
      "source": [
        "We can use the `trimesh` package to read and visualize the `.off` mesh files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zUqnRCN8rnA0",
        "outputId": "397e4e27-9e4c-4372-cc00-153608d7af0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "string is not a file: `/root/.keras/datasets/ModelNet10/chair/train/chair_0001.off`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4ef2933a5e46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrimesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"chair/train/chair_0001.off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trimesh/exchange/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_obj, file_type, resolver, force, allow_remote, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# call the most general loading case into a `Scene`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     loaded = load_scene(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mfile_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mfile_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trimesh/exchange/load.py\u001b[0m in \u001b[0;36mload_scene\u001b[0;34m(file_obj, file_type, resolver, allow_remote, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# parse all possible values of file objects into simple types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     arg = _parse_file_args(\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mfile_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mfile_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trimesh/exchange/load.py\u001b[0m in \u001b[0;36m_parse_file_args\u001b[0;34m(file_obj, file_type, resolver, allow_remote, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"string is not a file: `{file_obj}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: string is not a file: `/root/.keras/datasets/ModelNet10/chair/train/chair_0001.off`"
          ]
        }
      ],
      "source": [
        "mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\n",
        "mesh.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u58xJFqwrnA0"
      },
      "source": [
        "To convert a mesh file to a point cloud we first need to sample points on the mesh\n",
        "surface. `.sample()` performs a unifrom random sampling. Here we sample at 2048 locations\n",
        "and visualize in `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VXjWU25rnA0"
      },
      "outputs": [],
      "source": [
        "points = mesh.sample(2048)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeHPSBEmrnA1"
      },
      "source": [
        "To generate a `tf.data.Dataset()` we need to first parse through the ModelNet data\n",
        "folders. Each mesh is loaded and sampled into a point cloud before being added to a\n",
        "standard python list and converted to a `numpy` array. We also store the current\n",
        "enumerate index value as the object label and use a dictionary to recall this later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF5xPLeNrnA1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def parse_dataset(num_points=2048):\n",
        "    train_points = []\n",
        "    train_labels = []\n",
        "    test_points = []\n",
        "    test_labels = []\n",
        "    class_map = {}\n",
        "    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
        "\n",
        "    for i, folder in enumerate(folders):\n",
        "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
        "        # store folder name with ID so we can retrieve later\n",
        "        class_map[i] = folder.split(\"/\")[-1]\n",
        "        # gather all files\n",
        "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
        "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
        "\n",
        "        for f in train_files:\n",
        "            train_points.append(trimesh.load(f).sample(num_points))\n",
        "            train_labels.append(i)\n",
        "\n",
        "        for f in test_files:\n",
        "            test_points.append(trimesh.load(f).sample(num_points))\n",
        "            test_labels.append(i)\n",
        "\n",
        "    return (\n",
        "        np.array(train_points),\n",
        "        np.array(test_points),\n",
        "        np.array(train_labels),\n",
        "        np.array(test_labels),\n",
        "        class_map,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNYPwvMrrnA1"
      },
      "source": [
        "Set the number of points to sample and batch size and parse the dataset. This can take\n",
        "~5minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSTHjNGUrnA1"
      },
      "outputs": [],
      "source": [
        "NUM_POINTS = 2048\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
        "    NUM_POINTS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjE-6V50rnA1"
      },
      "source": [
        "Our data can now be read into a `tf.data.Dataset()` object. We set the shuffle buffer\n",
        "size to the entire size of the dataset as prior to this the data is ordered by class.\n",
        "Data augmentation is important when working with point cloud data. We create a\n",
        "augmentation function to jitter and shuffle the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHXI6PZprnA1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def augment(points, label):\n",
        "    # jitter points\n",
        "    points += keras.random.uniform(points.shape, -0.005, 0.005, dtype=\"float64\")\n",
        "    # shuffle points\n",
        "    points = keras.random.shuffle(points)\n",
        "    return points, label\n",
        "\n",
        "\n",
        "train_size = 0.8\n",
        "dataset = tf_data.Dataset.from_tensor_slices((train_points, train_labels))\n",
        "test_dataset = tf_data.Dataset.from_tensor_slices((test_points, test_labels))\n",
        "train_dataset_size = int(len(dataset) * train_size)\n",
        "\n",
        "dataset = dataset.shuffle(len(train_points)).map(augment)\n",
        "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = dataset.take(train_dataset_size).batch(BATCH_SIZE)\n",
        "validation_dataset = dataset.skip(train_dataset_size).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqi3c3BgrnA1"
      },
      "source": [
        "### Build a model\n",
        "\n",
        "Each convolution and fully-connected layer (with exception for end layers) consits of\n",
        "Convolution / Dense -> Batch Normalization -> ReLU Activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfniRhA8rnA2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv_bn(x, filters):\n",
        "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "def dense_bn(x, filters):\n",
        "    x = layers.Dense(filters)(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dw_3PfkrnA2"
      },
      "source": [
        "PointNet consists of two core components. The primary MLP network, and the transformer\n",
        "net (T-net). The T-net aims to learn an affine transformation matrix by its own mini\n",
        "network. The T-net is used twice. The first time to transform the input features (n, 3)\n",
        "into a canonical representation. The second is an affine transformation for alignment in\n",
        "feature space (n, 3). As per the original paper we constrain the transformation to be\n",
        "close to an orthogonal matrix (i.e. ||X*X^T - I|| = 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aZ8t7mprnA2"
      },
      "outputs": [],
      "source": [
        "\n",
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = ops.eye(num_features)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = ops.reshape(x, (-1, self.num_features, self.num_features))\n",
        "        xxt = ops.tensordot(x, x, axes=(2, 2))\n",
        "        xxt = ops.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return ops.sum(self.l2reg * ops.square(xxt - self.eye))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ndQI-BsrnA2"
      },
      "source": [
        " We can then define a general function to build T-net layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdj8y1gQrnA2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tnet(inputs, num_features):\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "\n",
        "    x = conv_bn(inputs, 32)\n",
        "    x = conv_bn(x, 64)\n",
        "    x = conv_bn(x, 512)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = dense_bn(x, 256)\n",
        "    x = dense_bn(x, 128)\n",
        "    x = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(x)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpsUdcR5rnA2"
      },
      "source": [
        "The main network can be then implemented in the same manner where the t-net mini models\n",
        "can be dropped in a layers in the graph. Here we replicate the network architecture\n",
        "published in the original paper but with half the number of weights at each layer as we\n",
        "are using the smaller 10 class ModelNet dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_tHjz2jrnA2"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "\n",
        "x = tnet(inputs, 3)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = tnet(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 64)\n",
        "x = conv_bn(x, 512)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = dense_bn(x, 256)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = dense_bn(x, 128)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Eqxp6LrnA2"
      },
      "source": [
        "### Train model\n",
        "\n",
        "Once the model is defined it can be trained like any other standard classification model\n",
        "using `.compile()` and `.fit()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iidIXACgrnA3"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(train_dataset, epochs=20, validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US6aOw23rnA3"
      },
      "source": [
        "## Visualize predictions\n",
        "\n",
        "We can use matplotlib to visualize our trained model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3AX5zW-rnA3"
      },
      "outputs": [],
      "source": [
        "data = test_dataset.take(1)\n",
        "\n",
        "points, labels = list(data)[0]\n",
        "points = points[:8, ...]\n",
        "labels = labels[:8, ...]\n",
        "\n",
        "# run test data through model\n",
        "preds = model.predict(points)\n",
        "preds = ops.argmax(preds, -1)\n",
        "\n",
        "points = points.numpy()\n",
        "\n",
        "# plot points with predicted class and label\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "for i in range(8):\n",
        "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
        "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
        "    ax.set_title(\n",
        "        \"pred: {:}, label: {:}\".format(\n",
        "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
        "        )\n",
        "    )\n",
        "    ax.set_axis_off()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pointnet",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}